{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import chdir\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# local import (Hirotaka's myfunctions.py script)\n",
    "import myfunctions as myfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'temp': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir temp\n",
    "chdir('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the id file, covariate file (all European)\n",
    "wgsfolder = '/data/CARD/PD/GENOMES/august19/genotypes'\n",
    "idfile = '_keep.id'\n",
    "demog = pd.read_csv('/data/LNG/iwakih2/ampPD/data1_out/PP_PD_BF_HB_LC_demog.csv')\n",
    "euro = pd.read_csv(f'{wgsfolder}/PCA_filtered_europeans.txt', sep=' ',\n",
    "                  header=None, names=['FID', 'IID'])\n",
    "# df = pd.merge(demog, euro, left_on='WGSID', right_on='IID')\n",
    "df = demog\n",
    "df['FID'] = df.WGSID\n",
    "df['IID'] = df.WGSID\n",
    "df.RECRUIT=['CTR' if i=='HC' else i for i in df.RECRUIT]\n",
    "df = df[df.RECRUIT.isin(['CTR', 'PD'])]\n",
    "df = df[df.RECRUIT==df.LASTDIAG]\n",
    "df['pheno'] = [1 if i=='PD' else 0 for i in df.RECRUIT]\n",
    "df['AAD'] = df.AADi.where(df.pheno==0, other=df.AAOi)\n",
    "df['AGE'] = df.AGEatBL.where(df.pheno==0, other=df.AAD)\n",
    "\n",
    "df[['FID', 'IID', 'pheno']].to_csv(idfile, index=False, sep='\\t', header=None)\n",
    "df[['FID', 'IID', 'AGE', 'FEMALE']].to_csv('_qcovar.txt', index=False, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chrnum in range(1,23):\n",
    "#     pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "#     out = f'{wgsfolder}/merge/pd.june2019.chr{chrnum}.sqc'\n",
    "#     plinkcmd = f'\\\n",
    "#  plink2 --pfile {pfile}\\\n",
    "#  --make-bed\\\n",
    "#  --out {out}'\n",
    "#    myfunc.shell_do(plinkcmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_mergelist.txt', 'w') as f:\n",
    "#     for chrnum in range(1,23):\n",
    "#         bfile = f'{wgsfolder}/merge/pd.june2019.chr{chrnum}.sqc'\n",
    "#         f.write(f'{bfile}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergecmd = f'\\\n",
    "# plink --merge-list _mergelist.txt\\\n",
    "#  --make-bed\\\n",
    "#  --out {wgsfolder}/merge/pd.june2019.sqc'\n",
    "# with open('_merge_batch_script.sh', 'w') as f:\n",
    "#     f.write('#!/bin/bash\\n')\n",
    "#     f.write('module load plink\\n')\n",
    "#     f.write(f'{mergecmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sbatch _merge_batch_script.sh --cpus-per-task=128 --mem=100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plink2 --pfile /data/CARD/PD/GENOMES/august19/genotypes/pd.june2019.chr1.sqc --pca 50 --out chr1.pca\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('_pca.swarm', 'w') as f:\n",
    "    for chrnum in range(1,2):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        out_pcs = f'chr{chrnum}.pca'\n",
    "        plink_pca_cmd = f'\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --pca 50\\\n",
    " --out {out_pcs}\\n'\n",
    "        \n",
    "        f.write(plink_pca_cmd)\n",
    "        print(plink_pca_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60297240\n"
     ]
    }
   ],
   "source": [
    "!swarm -f _pca.swarm -g 64 --time=10:00:00 -t 20 --logdir swarm --module plink/2.0_alpha_1_final --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script1.sh', 'w') as f:\n",
    "    for chrnum in range(1,):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --keep {idfile} \\\n",
    " --freq \\\n",
    " --out {freqfile}\\n\"\n",
    "        f.write(plinkcmd)\n",
    "#         myfunc.shell_do(plinkcmd)\n",
    "print(f'{plinkcmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda/envs/py3.7/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "# client should match the qued number of threads\n",
    "client = Client(processes=False, threads_per_worker=2,\n",
    "                n_workers=2, memory_limit='30GB')\n",
    "# import dask\n",
    "import dask.dataframe as dd\n",
    "def MAFbin(x):\n",
    "    if x>0:\n",
    "        if x<0.001:\n",
    "            return(1)\n",
    "        elif x<0.01:\n",
    "            return(2)\n",
    "        elif x<0.1:\n",
    "            return(3)\n",
    "        elif x<0.2:\n",
    "            return(4)\n",
    "        elif x<0.3:\n",
    "            return(5)\n",
    "        elif x<0.4:\n",
    "            return(6)\n",
    "        else:\n",
    "            return(7)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrnum in range(1,23):\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "\n",
    "    df = dd.read_csv(f'{freqfile}.afreq', sep='\\t')\n",
    "    df['MAF'] = df.ALT_FREQS.where(cond=df.ALT_FREQS<=0.5, other=1-df.ALT_FREQS)\n",
    "    df['Group'] = df.MAF.apply(MAFbin, meta=('MAF', 'float64'))\n",
    "    for i in range(1,8):\n",
    "        df.loc[df.Group==i, ['ID']].to_csv(\n",
    "            f'{freqfile}.mafbin{i}', index=False, single_file=True)\n",
    "    print(f'chr{chrnum} finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script2.swarm', 'w') as f:\n",
    "    for chrnum in range(1,23):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        for Indx in range(1,8):\n",
    "            mafbinIndx = f'mafbin{Indx}'\n",
    "            mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "            plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --extract {mafbinfile}\\\n",
    " --keep {idfile}\\\n",
    " --make-bed\\\n",
    " --out {mafbinfile}\"\n",
    "            gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin'\n",
    "\n",
    "            f.write(f'{plinkcmd} && {gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _script2.swarm --time=40:00:00 -g 64 -t 10 --logdir swarm --module GCTA --partition=norm --devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rerun for jobs that were killed\n",
    "outputs = glob.glob('freq.*.mafbin*.ldbin.score.ld')\n",
    "# len(glob.glob('*.ldbin.log'))\n",
    "expected_out = ['freq.' + str(i) + '.mafbin' + str(j) + '.ldbin.score.ld' for i in range(1,23) for j in range(1,8)]\n",
    "missing = [bed.replace('.ldbin.score.ld', '') for bed in list(set(expected_out) - set(outputs))]\n",
    "\n",
    "with open('_rerunscript.swarm', 'w') as f:\n",
    "    for mafbinfile in missing:\n",
    "        gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin\\\n",
    " --thread-num 10'\n",
    "\n",
    "        f.write(f'{gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _rerunscript.swarm --time=40:00:00 -g 64 -t 10 --logdir swarm --module GCTA --partition=norm --devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrnum in range(1,23):\n",
    "    pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(1,8):\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # Note this is the ldscore within the maf bin\n",
    "        df = dd.read_csv(f'{mafbinfile}.ldbin.score.ld', sep=' ')\n",
    "        ldscvec = df.ldscore_SNP.compute()\n",
    "        ldscThres = ldscvec.median()\n",
    "        df['Group'] = 1\n",
    "        df['Group'] = df.Group.where(cond=df.ldscore_SNP<ldscThres, other=2)\n",
    "\n",
    "\n",
    "        # Create ldbin and GRMs within the ldbin\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "            df.loc[df.Group==i, ['SNP']].to_csv(\n",
    "                f'{ldbinIndx}', index=False, single_file=True)\n",
    "            gctacmd2 = f'\\\n",
    "            gcta64 --bfile {mafbinfile}\\\n",
    " --extract {ldbinIndx}\\\n",
    " --make-grm\\\n",
    " --out {ldbinIndx}'\n",
    "            myfunc.shell_do(gctacmd2)\n",
    "            print(gctacmd2)\n",
    "            with open('multi_GRMs.txt', 'a') as f:\n",
    "                f.write(f'{ldbinIndx}\\n')\n",
    "        # mafbin information save to mafbinInfo.csv\n",
    "        with open('mafbinInfo.txt', 'a') as f:\n",
    "            s = f'{chrnum}\\t{mafbinIndx}\\t{len(ldscvec)}\\t{ldscvec.mean()}\\t{ldscvec.median()}\\t{ldscvec.std()}'\n",
    "            f.write(f'{s}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: chr1.covar with 3387 samples\n"
     ]
    }
   ],
   "source": [
    "# create covar file per chrom and impute missing age (may want to consider dropping age column in this case (missing for more than half))\n",
    "# impute \"FEMALE\" with median\n",
    "for chrnum in range(1,2):\n",
    "    pcs_df = pd.read_csv(f'chr{chrnum}.pca.eigenvec', sep='\\t')\n",
    "    pcs_df.rename(columns={'#FID':'FID'}, inplace=True)\n",
    "    covar_df = df[['FID', 'IID', 'AGE', 'FEMALE']].merge(pcs_df, on=['FID','IID'])\n",
    "    covar_df.AGE.fillna(covar_df.AGE.mean(), inplace=True)\n",
    "    covar_df.FEMALE.fillna(covar_df.FEMALE.median(),inplace=True)\n",
    "#     print(f'dropping {covar_df[covar_df.AGE.isnull()].shape[0]} rows for missing age')\n",
    "#     covar_df.dropna(how='any', inplace=True)\n",
    "    covar_df.to_csv(f'chr{chrnum}.covar', index=False, sep=' ', header=None)\n",
    "    print(f'wrote: chr{chrnum}.covar with {covar_df.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9300, 52)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: gcta --reml --mgrm multi_GRMs.txt --pheno _fake_pheno.txt --qcovar chr1.pca.eigenvec --reml-no-lrt --thread-num 8 --out test\n"
     ]
    }
   ],
   "source": [
    "#  --pheno {idfile}\\\n",
    "\n",
    "gctacmd3 = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.txt\\\n",
    " --pheno _fake_pheno.txt\\\n",
    " --qcovar chr1.pca.eigenvec\\\n",
    " --reml-no-lrt\\\n",
    " --thread-num 8\\\n",
    " --out test'\n",
    "myfunc.shell_do(gctacmd3)\n",
    "\n",
    "# with open('_reml_script.sh', 'w') as f:\n",
    "#     f.write('#!/bin/bash\\n')\n",
    "#     f.write(f'{gctacmd3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60400321\n"
     ]
    }
   ],
   "source": [
    "!sbatch --mem=100g --cpus-per-task=64 _reml_script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3949\n",
       "0    3239\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['FID', 'IID', 'pheno']]\n",
    "df.pheno.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FID    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euro[['FID']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# making fake pheno data for testing\n",
    "euro['pheno'] = np.random.choice([0, 1], size=(euro.shape[0],), p=[2./3, 1./3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro.to_csv('_fake_pheno.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
