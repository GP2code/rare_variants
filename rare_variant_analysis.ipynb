{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Unloading plink  1.9.0-beta4.4  on cn0865 \n",
      "[+] Loading plink  2.0_alpha_1_final \n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) plink/1.9.0-beta4.4 => plink/2.0_alpha_1_final\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import chdir\n",
    "import subprocess\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import itertools\n",
    "!module load plink/2.0_alpha_1_final\n",
    "# local import (Hirotaka's myfunctions.py script)\n",
    "import myfunctions as myfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'temp': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir temp\n",
    "chdir('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the id file, covariate file (all European)\n",
    "wgsfolder = '/data/CARD/PD/GENOMES/august19/genotypes'\n",
    "# wgsfolder = '/data/CARD/PD/WGS/june2019'\n",
    "idfile = '_keep.id'\n",
    "demog = pd.read_csv('/data/LNG/iwakih2/ampPD/data1_out/PP_PD_BF_HB_LC_demog.csv')\n",
    "euro = pd.read_csv(f'/data/CARD/PD/GENOMES/august19/genotypes/PCA_filtered_europeans.txt', sep=' ',\n",
    "                  header=None, names=['FID', 'IID'])\n",
    "df = pd.merge(demog, euro, left_on='WGSID', right_on='IID')\n",
    "df['FID'] = df.WGSID\n",
    "df['IID'] = df.WGSID\n",
    "df.RECRUIT=['CTR' if i=='HC' else i for i in df.RECRUIT]\n",
    "df = df[df.RECRUIT.isin(['CTR', 'PD'])]\n",
    "df = df[df.RECRUIT==df.LASTDIAG]\n",
    "df['pheno'] = [1 if i=='PD' else 0 for i in df.RECRUIT]\n",
    "df['AAD'] = df.AADi.where(df.pheno==0, other=df.AAOi)\n",
    "df['AGE'] = df.AGEatBL.where(df.pheno==0, other=df.AAD)\n",
    "\n",
    "df[['FID', 'IID', 'pheno']].to_csv(idfile, index=False, sep='\\t', header=None)\n",
    "df[['FID', 'IID', 'AGE', 'FEMALE']].to_csv('_qcovar.txt', index=False, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used this to generate pca for chr1 just for testing purposes-- prune and merge all chrs first then run PCA\n",
    "with open('_pca.swarm', 'w') as f:\n",
    "    for chrnum in range(1,2):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        out_pcs = f'chr{chrnum}.pca'\n",
    "        plink_pca_cmd = f'\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --pca 280\\\n",
    " --out {out_pcs}\\n'\n",
    "#         myfunc.shell_do(plink_pca_cmd)\n",
    "        f.write(plink_pca_cmd)\n",
    "#         print(plink_pca_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62409389\n"
     ]
    }
   ],
   "source": [
    "!swarm -f _pca.swarm -g 64 --time=10:00:00 -t 20 --logdir swarm --module plink/2.0_alpha_1_final --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cut up pca for reml\n",
    "pca = pd.read_csv('chr1.pca.eigenvec', sep='\\t')\n",
    "pca20 = pca.iloc[:,0:22]\n",
    "pca20.to_csv('chr1.pca.20.eigenvec', sep='\\t',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script1.swarm', 'w') as f:\n",
    "    for chrnum in range(1,23):\n",
    "#         pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --keep {idfile} \\\n",
    " --freq \\\n",
    " --out {freqfile}\\n\"\n",
    "        f.write(plinkcmd)\n",
    "#         myfunc.shell_do(plinkcmd)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62413952\n"
     ]
    }
   ],
   "source": [
    "!swarm -f _script1.swarm -g 64 --time=10:00:00 -t 20 --logdir swarm --module plink/2.0_alpha_1_final --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "# client should match the qued number of threads\n",
    "client = Client(processes=False, threads_per_worker=2,\n",
    "                n_workers=2, memory_limit='30GB')\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def MAFbin(x):\n",
    "    if x>0.05:\n",
    "        if x<0.25:\n",
    "            return(1)\n",
    "        else:\n",
    "            return(2)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# testing out just 2 maf bins\n",
    "# def MAFbin(x):\n",
    "#     if x>0:\n",
    "#         if x<0.01:\n",
    "#             return(1)\n",
    "#         else:\n",
    "#             return(2)\n",
    "#     else:\n",
    "#         return(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#try testing fewer maf bins\n",
    "# def MAFbin(x):\n",
    "#     if x>0:\n",
    "#         if x<0.001:\n",
    "#             return(1)\n",
    "#         elif x<0.01:\n",
    "#             return(2)\n",
    "#         elif x<0.1:\n",
    "#             return(3)\n",
    "#         elif x<0.25:\n",
    "#             return(4)\n",
    "#         elif x<0.5:\n",
    "#             return(5)\n",
    "#         else:\n",
    "#             return(6)\n",
    "#     else:\n",
    "#         return(0)\n",
    "\n",
    "\n",
    "\n",
    "# def MAFbin(x):\n",
    "#     if x>0:\n",
    "#         if x<0.001:\n",
    "#             return(1)\n",
    "#         elif x<0.01:\n",
    "#             return(2)\n",
    "#         elif x<0.1:\n",
    "#             return(3)\n",
    "#         elif x<0.2:\n",
    "#             return(4)\n",
    "#         elif x<0.3:\n",
    "#             return(5)\n",
    "#         elif x<0.4:\n",
    "#             return(6)\n",
    "#         else:\n",
    "#             return(7)\n",
    "#     else:\n",
    "#         return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1 finished\n",
      "chr2 finished\n",
      "chr3 finished\n",
      "chr4 finished\n",
      "chr5 finished\n",
      "chr6 finished\n",
      "chr7 finished\n",
      "chr8 finished\n",
      "chr9 finished\n",
      "chr10 finished\n",
      "chr11 finished\n",
      "chr12 finished\n",
      "chr13 finished\n",
      "chr14 finished\n",
      "chr15 finished\n",
      "chr16 finished\n",
      "chr17 finished\n",
      "chr18 finished\n",
      "chr19 finished\n",
      "chr20 finished\n",
      "chr21 finished\n",
      "chr22 finished\n"
     ]
    }
   ],
   "source": [
    "# total_counts_df = pd.DataFrame(index=[0,1,2,3,4,5,6])\n",
    "#test for 2 maf bins\n",
    "total_counts_df = pd.DataFrame(index=[0,1,2])\n",
    "\n",
    "for chrnum in range(1,23):\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "\n",
    "    df = dd.read_csv(f'{freqfile}.afreq', sep='\\t')\n",
    "    df['MAF'] = df.ALT_FREQS.where(cond=df.ALT_FREQS<=0.5, other=1-df.ALT_FREQS)\n",
    "    df['Group'] = df.MAF.apply(MAFbin, meta=('MAF', 'float64'))\n",
    "    for i in range(1,3):\n",
    "        df.loc[df.Group==i, ['ID']].to_csv(\n",
    "            f'{freqfile}.mafbin{i}', index=False, single_file=True)\n",
    "    print(f'chr{chrnum} finished')\n",
    "    total_counts_df[chrnum] = pd.DataFrame(df.groupby('Group').ID.count().compute())\n",
    "#     total_counts_df.merge(counts_df, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 23 elements, new values have 22 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-76b73fd09987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # add chr names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtotal_counts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5192\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise ValueError(\n\u001b[1;32m    182\u001b[0m                 \u001b[0;34m\"Length mismatch: Expected axis has {old} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0;34m\"values have {new} elements\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 23 elements, new values have 22 elements"
     ]
    }
   ],
   "source": [
    "# # add chr names\n",
    "chrs = ['chr' + str(i) for i in range(1,23)]\n",
    "total_counts_df.columns = chrs\n",
    "\n",
    "# add bins\n",
    "# bins = ['0.000', '<0.001', '<0.01', '<0.1', '<0.25', '<0.5', '=0.5']\n",
    "# bins = ['0.000', '<0.01', '>=0.01']\n",
    "bins = ['<0.05', '<0.25', '>=0.25']\n",
    "total_counts_df['bin'] = bins\n",
    "total_counts_df.set_index('bin', inplace=True)\n",
    "total_counts_df['total'] = total_counts_df.sum(axis=1)\n",
    "total_counts_df.to_csv('_maf_bin_counts.txt', sep='\\t')\n",
    "total_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqfile = f'freq.21'\n",
    "\n",
    "# df = pd.read_csv(f'{freqfile}.afreq', sep='\\t')\n",
    "# df['MAF'] = df.ALT_FREQS.where(cond=df.ALT_FREQS<=0.5, other=1-df.ALT_FREQS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Group'] = df.MAF.apply(MAFbin)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.Group == 6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script2.swarm', 'w') as f:\n",
    "    for chrnum in range(1,23):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        for Indx in range(1,3):\n",
    "            mafbinIndx = f'mafbin{Indx}'\n",
    "            mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "            plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --extract {mafbinfile}\\\n",
    " --keep {idfile}\\\n",
    " --make-bed\\\n",
    " --out {mafbinfile}\"\n",
    "            gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin\\\n",
    " --thread-num 10'\n",
    "\n",
    "            f.write(f'{plinkcmd} && {gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62425618\n"
     ]
    }
   ],
   "source": [
    "!swarm -f _script2.swarm --time=40:00:00 -g 64 -t 64 --logdir swarm --module GCTA,plink/2.0_alpha_1_final --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rerun for jobs that were killed\n",
    "outputs = glob.glob('freq.*.mafbin*.ldbin.score.ld')\n",
    "# len(glob.glob('*.ldbin.log'))\n",
    "expected_out = ['freq.' + str(i) + '.mafbin' + str(j) + '.ldbin.score.ld' for i in range(1,23) for j in range(1,3)]\n",
    "missing = [bed.replace('.ldbin.score.ld', '') for bed in list(set(expected_out) - set(outputs))]\n",
    "\n",
    "with open('_rerunscript.swarm', 'w') as f:\n",
    "    for mafbinfile in missing:\n",
    "        gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin\\\n",
    " --thread-num 10'\n",
    "\n",
    "        f.write(f'{gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _rerunscript.swarm --time=40:00:00 -g 64 -t 10 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: gcta64 --bfile freq.1.mafbin1 --extract freq.1.mafbin1.ldbin1 --make-grm --out freq.1.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.1.mafbin1 --extract freq.1.mafbin1.ldbin2 --make-grm --out freq.1.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.1.mafbin2 --extract freq.1.mafbin2.ldbin1 --make-grm --out freq.1.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.1.mafbin2 --extract freq.1.mafbin2.ldbin2 --make-grm --out freq.1.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.2.mafbin1 --extract freq.2.mafbin1.ldbin1 --make-grm --out freq.2.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.2.mafbin1 --extract freq.2.mafbin1.ldbin2 --make-grm --out freq.2.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.2.mafbin2 --extract freq.2.mafbin2.ldbin1 --make-grm --out freq.2.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.2.mafbin2 --extract freq.2.mafbin2.ldbin2 --make-grm --out freq.2.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.3.mafbin1 --extract freq.3.mafbin1.ldbin1 --make-grm --out freq.3.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.3.mafbin1 --extract freq.3.mafbin1.ldbin2 --make-grm --out freq.3.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.3.mafbin2 --extract freq.3.mafbin2.ldbin1 --make-grm --out freq.3.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.3.mafbin2 --extract freq.3.mafbin2.ldbin2 --make-grm --out freq.3.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.4.mafbin1 --extract freq.4.mafbin1.ldbin1 --make-grm --out freq.4.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.4.mafbin1 --extract freq.4.mafbin1.ldbin2 --make-grm --out freq.4.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.4.mafbin2 --extract freq.4.mafbin2.ldbin1 --make-grm --out freq.4.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.4.mafbin2 --extract freq.4.mafbin2.ldbin2 --make-grm --out freq.4.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.5.mafbin1 --extract freq.5.mafbin1.ldbin1 --make-grm --out freq.5.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.5.mafbin1 --extract freq.5.mafbin1.ldbin2 --make-grm --out freq.5.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.5.mafbin2 --extract freq.5.mafbin2.ldbin1 --make-grm --out freq.5.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.5.mafbin2 --extract freq.5.mafbin2.ldbin2 --make-grm --out freq.5.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.6.mafbin1 --extract freq.6.mafbin1.ldbin1 --make-grm --out freq.6.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.6.mafbin1 --extract freq.6.mafbin1.ldbin2 --make-grm --out freq.6.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.6.mafbin2 --extract freq.6.mafbin2.ldbin1 --make-grm --out freq.6.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.6.mafbin2 --extract freq.6.mafbin2.ldbin2 --make-grm --out freq.6.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.7.mafbin1 --extract freq.7.mafbin1.ldbin1 --make-grm --out freq.7.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.7.mafbin1 --extract freq.7.mafbin1.ldbin2 --make-grm --out freq.7.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.7.mafbin2 --extract freq.7.mafbin2.ldbin1 --make-grm --out freq.7.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.7.mafbin2 --extract freq.7.mafbin2.ldbin2 --make-grm --out freq.7.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.8.mafbin1 --extract freq.8.mafbin1.ldbin1 --make-grm --out freq.8.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.8.mafbin1 --extract freq.8.mafbin1.ldbin2 --make-grm --out freq.8.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.8.mafbin2 --extract freq.8.mafbin2.ldbin1 --make-grm --out freq.8.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.8.mafbin2 --extract freq.8.mafbin2.ldbin2 --make-grm --out freq.8.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.9.mafbin1 --extract freq.9.mafbin1.ldbin1 --make-grm --out freq.9.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.9.mafbin1 --extract freq.9.mafbin1.ldbin2 --make-grm --out freq.9.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.9.mafbin2 --extract freq.9.mafbin2.ldbin1 --make-grm --out freq.9.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.9.mafbin2 --extract freq.9.mafbin2.ldbin2 --make-grm --out freq.9.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.10.mafbin1 --extract freq.10.mafbin1.ldbin1 --make-grm --out freq.10.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.10.mafbin1 --extract freq.10.mafbin1.ldbin2 --make-grm --out freq.10.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.10.mafbin2 --extract freq.10.mafbin2.ldbin1 --make-grm --out freq.10.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.10.mafbin2 --extract freq.10.mafbin2.ldbin2 --make-grm --out freq.10.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.11.mafbin1 --extract freq.11.mafbin1.ldbin1 --make-grm --out freq.11.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.11.mafbin1 --extract freq.11.mafbin1.ldbin2 --make-grm --out freq.11.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.11.mafbin2 --extract freq.11.mafbin2.ldbin1 --make-grm --out freq.11.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.11.mafbin2 --extract freq.11.mafbin2.ldbin2 --make-grm --out freq.11.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.12.mafbin1 --extract freq.12.mafbin1.ldbin1 --make-grm --out freq.12.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.12.mafbin1 --extract freq.12.mafbin1.ldbin2 --make-grm --out freq.12.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.12.mafbin2 --extract freq.12.mafbin2.ldbin1 --make-grm --out freq.12.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.12.mafbin2 --extract freq.12.mafbin2.ldbin2 --make-grm --out freq.12.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.13.mafbin1 --extract freq.13.mafbin1.ldbin1 --make-grm --out freq.13.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.13.mafbin1 --extract freq.13.mafbin1.ldbin2 --make-grm --out freq.13.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.13.mafbin2 --extract freq.13.mafbin2.ldbin1 --make-grm --out freq.13.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.13.mafbin2 --extract freq.13.mafbin2.ldbin2 --make-grm --out freq.13.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.14.mafbin1 --extract freq.14.mafbin1.ldbin1 --make-grm --out freq.14.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.14.mafbin1 --extract freq.14.mafbin1.ldbin2 --make-grm --out freq.14.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.14.mafbin2 --extract freq.14.mafbin2.ldbin1 --make-grm --out freq.14.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.14.mafbin2 --extract freq.14.mafbin2.ldbin2 --make-grm --out freq.14.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.15.mafbin1 --extract freq.15.mafbin1.ldbin1 --make-grm --out freq.15.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.15.mafbin1 --extract freq.15.mafbin1.ldbin2 --make-grm --out freq.15.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.15.mafbin2 --extract freq.15.mafbin2.ldbin1 --make-grm --out freq.15.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.15.mafbin2 --extract freq.15.mafbin2.ldbin2 --make-grm --out freq.15.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.16.mafbin1 --extract freq.16.mafbin1.ldbin1 --make-grm --out freq.16.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.16.mafbin1 --extract freq.16.mafbin1.ldbin2 --make-grm --out freq.16.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.16.mafbin2 --extract freq.16.mafbin2.ldbin1 --make-grm --out freq.16.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.16.mafbin2 --extract freq.16.mafbin2.ldbin2 --make-grm --out freq.16.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.17.mafbin1 --extract freq.17.mafbin1.ldbin1 --make-grm --out freq.17.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.17.mafbin1 --extract freq.17.mafbin1.ldbin2 --make-grm --out freq.17.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.17.mafbin2 --extract freq.17.mafbin2.ldbin1 --make-grm --out freq.17.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.17.mafbin2 --extract freq.17.mafbin2.ldbin2 --make-grm --out freq.17.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.18.mafbin1 --extract freq.18.mafbin1.ldbin1 --make-grm --out freq.18.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.18.mafbin1 --extract freq.18.mafbin1.ldbin2 --make-grm --out freq.18.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.18.mafbin2 --extract freq.18.mafbin2.ldbin1 --make-grm --out freq.18.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.18.mafbin2 --extract freq.18.mafbin2.ldbin2 --make-grm --out freq.18.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.19.mafbin1 --extract freq.19.mafbin1.ldbin1 --make-grm --out freq.19.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.19.mafbin1 --extract freq.19.mafbin1.ldbin2 --make-grm --out freq.19.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.19.mafbin2 --extract freq.19.mafbin2.ldbin1 --make-grm --out freq.19.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.19.mafbin2 --extract freq.19.mafbin2.ldbin2 --make-grm --out freq.19.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.20.mafbin1 --extract freq.20.mafbin1.ldbin1 --make-grm --out freq.20.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.20.mafbin1 --extract freq.20.mafbin1.ldbin2 --make-grm --out freq.20.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.20.mafbin2 --extract freq.20.mafbin2.ldbin1 --make-grm --out freq.20.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.20.mafbin2 --extract freq.20.mafbin2.ldbin2 --make-grm --out freq.20.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.21.mafbin1 --extract freq.21.mafbin1.ldbin1 --make-grm --out freq.21.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.21.mafbin1 --extract freq.21.mafbin1.ldbin2 --make-grm --out freq.21.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.21.mafbin2 --extract freq.21.mafbin2.ldbin1 --make-grm --out freq.21.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.21.mafbin2 --extract freq.21.mafbin2.ldbin2 --make-grm --out freq.21.mafbin2.ldbin2\n",
      "Executing: gcta64 --bfile freq.22.mafbin1 --extract freq.22.mafbin1.ldbin1 --make-grm --out freq.22.mafbin1.ldbin1\n",
      "Executing: gcta64 --bfile freq.22.mafbin1 --extract freq.22.mafbin1.ldbin2 --make-grm --out freq.22.mafbin1.ldbin2\n",
      "Executing: gcta64 --bfile freq.22.mafbin2 --extract freq.22.mafbin2.ldbin1 --make-grm --out freq.22.mafbin2.ldbin1\n",
      "Executing: gcta64 --bfile freq.22.mafbin2 --extract freq.22.mafbin2.ldbin2 --make-grm --out freq.22.mafbin2.ldbin2\n"
     ]
    }
   ],
   "source": [
    "for chrnum in range(1,23):\n",
    "    pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(1,3):\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # Note this is the ldscore within the maf bin\n",
    "        df = dd.read_csv(f'{mafbinfile}.ldbin.score.ld', sep=' ')\n",
    "        ldscvec = df.ldscore_SNP.compute()\n",
    "        ldscThres = ldscvec.median()\n",
    "        df['Group'] = 1\n",
    "        df['Group'] = df.Group.where(cond=df.ldscore_SNP<ldscThres, other=2)\n",
    "\n",
    "\n",
    "        # Create ldbin and GRMs within the ldbin\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "            df.loc[df.Group==i, ['SNP']].to_csv(\n",
    "                f'{ldbinIndx}', index=False, single_file=True)\n",
    "            gctacmd2 = f'\\\n",
    "            gcta64 --bfile {mafbinfile}\\\n",
    " --extract {ldbinIndx}\\\n",
    " --make-grm\\\n",
    " --out {ldbinIndx}'\n",
    "            myfunc.shell_do(gctacmd2)\n",
    "            with open('multi_GRMs.txt', 'a') as f:\n",
    "                f.write(f'{ldbinIndx}\\n')\n",
    "        # mafbin information save to mafbinInfo.csv\n",
    "        with open('mafbinInfo.txt', 'a') as f:\n",
    "            s = f'{chrnum}\\t{mafbinIndx}\\t{len(ldscvec)}\\t{ldscvec.mean()}\\t{ldscvec.median()}\\t{ldscvec.std()}'\n",
    "            f.write(f'{s}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create covar file per chrom and impute missing age (may want to consider dropping age column in this case (missing for more than half))\n",
    "# impute \"FEMALE\" with median\n",
    "# for chrnum in range(1,2):\n",
    "#     pcs_df = pd.read_csv(f'chr{chrnum}.pca.eigenvec', sep='\\t')\n",
    "#     pcs_df.rename(columns={'#FID':'FID'}, inplace=True)\n",
    "#     covar_df = df[['FID', 'IID', 'AGE', 'FEMALE']].merge(pcs_df, on=['FID','IID'])\n",
    "#     covar_df.drop(['AGE','FEMALE'], axis=1, inplace=True)\n",
    "# #     covar_df.AGE.fillna(covar_df.AGE.mean(), inplace=True)\n",
    "# #     covar_df.FEMALE.fillna(covar_df.FEMALE.median(),inplace=True)\n",
    "# #     print(f'dropping {covar_df[covar_df.AGE.isnull()].shape[0]} rows for missing age')\n",
    "# #     covar_df.dropna(how='any', inplace=True)\n",
    "#     covar_df.to_csv(f'chr{chrnum}.covar', index=False, sep=' ', header=None)\n",
    "#     print(f'wrote: chr{chrnum}.covar with {covar_df.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count in each ld bin\n",
    "high_ld_counts_dict = {i:0 for i in range(1,3)}\n",
    "low_ld_counts_dict = {i:0 for i in range(1,3)}\n",
    "\n",
    "for chrnum in range(1,23):\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(1,3):\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "            ldbin_df = pd.read_csv(ldbinIndx,sep='\\t')\n",
    "            if (i == 1):\n",
    "                low_ld_counts_dict[Indx] += ldbin_df.shape[0]\n",
    "            else:\n",
    "                high_ld_counts_dict[Indx] += ldbin_df.shape[0]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high ld counts per maf group: {1: 2654790, 2: 1834907}\n",
      "low ld counts per maf group: {1: 2654756, 2: 1834870}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high_ld</th>\n",
       "      <th>low_ld</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maf_bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;0.01</th>\n",
       "      <td>2654790</td>\n",
       "      <td>2654756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;=0.01</th>\n",
       "      <td>1834907</td>\n",
       "      <td>1834870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         high_ld   low_ld\n",
       "maf_bin                  \n",
       "<0.01    2654790  2654756\n",
       ">=0.01   1834907  1834870"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'high ld counts per maf group: {high_ld_counts_dict}')\n",
    "print(f'low ld counts per maf group: {low_ld_counts_dict}')\n",
    "high_df = pd.Series(high_ld_counts_dict).to_frame()\n",
    "low_df = pd.Series(low_ld_counts_dict).to_frame()\n",
    "high_df.columns = ['high_ld']\n",
    "low_df.columns = ['low_ld']\n",
    "ld_counts_df = high_df.merge(low_df, left_index=True, right_index=True)\n",
    "# bins = ['<0.001', '<0.01', '<0.1', '<0.25', '<0.5', '=0.5']\n",
    "bins = ['<0.01','>=0.01']\n",
    "ld_counts_df['maf_bin'] = bins\n",
    "ld_counts_df.set_index('maf_bin', inplace=True)\n",
    "ld_counts_df.to_csv('_ld_bin_counts.txt', sep='\\t')\n",
    "ld_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --reml-no-lrt\\\n",
    "# --reml-inv-mtd 3\\\n",
    "# run with all maf bins\n",
    "# gctacmd3 = f'\\\n",
    "# gcta --reml\\\n",
    "#  --mgrm multi_GRMs.txt\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.10.eigenvec\\\n",
    "#  --reml-alg 2\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test'\n",
    "# # myfunc.shell_do(gctacmd3)\n",
    "\n",
    "# with open('_reml_script.swarm', 'w') as f:\n",
    "# #     f.write('#!/bin/bash\\n')\n",
    "#     f.write(f'{gctacmd3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set up to run with just maf bins 2-6 as we might not have resolution for maf<0.001\n",
    "# for chrnum in range(1,23):\n",
    "#     pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "#     freqfile = f'freq.{chrnum}'\n",
    "#     for Indx in range(2,6): # leaving last maf bin out for testing!!!! ( will be combined with 0.25<maf<=0.5)\n",
    "#         mafbinIndx = f'mafbin{Indx}'\n",
    "#         mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#         # Note this is the ldscore within the maf bin\n",
    "#         df = dd.read_csv(f'{mafbinfile}.ldbin.score.ld', sep=' ')\n",
    "#         ldscvec = df.ldscore_SNP.compute()\n",
    "#         ldscThres = ldscvec.median()\n",
    "#         df['Group'] = 1\n",
    "#         df['Group'] = df.Group.where(cond=df.ldscore_SNP<ldscThres, other=2)\n",
    "\n",
    "\n",
    "#         # Create ldbin and GRMs within the ldbin\n",
    "#         for i in range(1, 3):\n",
    "#             ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "\n",
    "#             with open('2_5_maf_bins_multi_GRMs.txt', 'a') as f:\n",
    "#                 f.write(f'{ldbinIndx}\\n')\n",
    "#         # mafbin information save to mafbinInfo.csv\n",
    "#         with open('2_5_mafbinInfo.txt', 'a') as f:\n",
    "#             s = f'{chrnum}\\t{mafbinIndx}\\t{len(ldscvec)}\\t{ldscvec.mean()}\\t{ldscvec.median()}\\t{ldscvec.std()}'\n",
    "#             f.write(f'{s}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gctacmd_2_5_maf = f'\\\n",
    "# gcta --reml\\\n",
    "#  --mgrm 2_5_maf_bins_multi_GRMs.txt\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.eigenvec\\\n",
    "#  --reml-alg 2\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test_2_5_maf'\n",
    "# # myfunc.shell_do(gctacmd3)\n",
    "\n",
    "# with open('2_5_maf_bins_reml_script.swarm', 'w') as f:\n",
    "# #     f.write('#!/bin/bash\\n')\n",
    "#     f.write(f'{gctacmd_2_5_maf}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f 2_5_maf_bins_reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get estimates for cpu-hrs for analysis\n",
    "jobs_df = pd.read_csv('../biowulf_user_dashboard.csv')\n",
    "jobs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df2 = jobs_df[jobs_df.state == 'COMPLETED'][['jobid','cpu', 'cpu_min',\n",
    "       'cpu_max', 'cpu_avg', 'cpu_util', 'mem', 'mem_min', 'mem_max','elapsed_time']]\n",
    "\n",
    "jobs_df2['hrs'] = jobs_df2.elapsed_time/3600\n",
    "jobs_df2['cpu_hrs'] = jobs_df2.cpu * jobs_df2.hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(jobs_df2.cpu_hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try merging grms\n",
    "\n",
    "# !gcta --mgrm multi_GRMs.txt --make-grm --out test_merged_grm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gctacmd_merged = f'\\\n",
    "# gcta --reml\\\n",
    "#  --grm test_merged_grm\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.eigenvec\\\n",
    "#  --reml-alg 2\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test_merged'\n",
    "\n",
    "# with open('merged_reml_script.swarm', 'w') as f:\n",
    "# #     f.write('#!/bin/bash\\n')\n",
    "#     f.write(f'{gctacmd_merged}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f merged_reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_ids = pd.read_csv('_keep.id',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_ids[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: gcta --mgrm multi_GRMs.mafbin1.ldbin1.txt --make-grm --out freq.mafbin1.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin1.ldbin2.txt --make-grm --out freq.mafbin1.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin2.ldbin1.txt --make-grm --out freq.mafbin2.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin2.ldbin2.txt --make-grm --out freq.mafbin2.ldbin2\n"
     ]
    }
   ],
   "source": [
    "# now merge chr grms (1 grm per mafbin/ldbin combo: 6 maf bins, 2 ldbins = 12 total grms)\n",
    "\n",
    "with open('multi_GRMs.merged_chrs.txt', 'w') as mergedGRMlist:\n",
    "    for Indx in range(1,3): \n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinIndx}.ldbin{i}'\n",
    "            mergedGRMfile = f'freq.{ldbinIndx}'\n",
    "            for chrnum in range(1,23):\n",
    "                freqfile = f'freq.{chrnum}.{ldbinIndx}'\n",
    "                multiGRMfile = f'multi_GRMs.{ldbinIndx}.txt'\n",
    "                with open(f'{multiGRMfile}', 'a') as f:\n",
    "                    f.write(f'{freqfile}\\n')\n",
    "            \n",
    "            gcta_merge_cmd = f'\\\n",
    "gcta --mgrm {multiGRMfile}\\\n",
    " --make-grm --out {mergedGRMfile}'\n",
    "            myfunc.shell_do(gcta_merge_cmd)\n",
    "            mergedGRMlist.write(f'{mergedGRMfile}\\n')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  \n",
    "# gctacmd_merged_chrs_reml = f'\\\n",
    "# gcta --reml\\\n",
    "#  --mgrm multi_GRMs.merged_chrs.txt\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.10.eigenvec\\\n",
    "#  --reml-alg 1\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test_alg1'\n",
    "\n",
    "# with open('_reml_alg1_script.swarm', 'w') as f:\n",
    "#     f.write(f'{gctacmd_merged_chrs_reml}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _reml_alg1_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gctacmd_merged_chrs_reml = f'\\\n",
    "# gcta --reml\\\n",
    "#  --mgrm multi_GRMs.merged_chrs.txt\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.10.eigenvec\\\n",
    "#  --reml-alg 2\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test_alg2'\n",
    "\n",
    "# with open('_reml_alg2_script.swarm', 'w') as f:\n",
    "#     f.write(f'{gctacmd_merged_chrs_reml}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _reml_alg2_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm --devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fire off jobs in a loop like gridsearch\n",
    "# \n",
    "param_grid = {'--reml-inv-mtd': [None, 3, 4], \n",
    "              '--reml-alg': [0, 1, 2]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --reml-no-constrain\\\n",
    "\n",
    "reml_gridsearch_cmds = []\n",
    "for opts in itertools.product(param_grid['--reml-alg'], param_grid['--reml-inv-mtd']):\n",
    "    if opts[1]:\n",
    "        gctacmd = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.merged_chrs.txt\\\n",
    " --pheno {idfile}\\\n",
    " --qcovar chr1.pca.20.eigenvec\\\n",
    " --reml-alg {opts[0]}\\\n",
    " --reml-inv-mtd {opts[1]}\\\n",
    " --reml-no-lrt\\\n",
    " --thread-num 64\\\n",
    " --reml-maxit 1000\\\n",
    " --out reml_no_constrain/test_alg{opts[0]}_invmtd{opts[1]}_lrt'\n",
    "        reml_gridsearch_cmds.append(gctacmd) \n",
    "    else:\n",
    "        gctacmd = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.merged_chrs.txt\\\n",
    " --pheno {idfile}\\\n",
    " --qcovar chr1.pca.20.eigenvec\\\n",
    " --reml-alg {opts[0]}\\\n",
    " --thread-num 64\\\n",
    " --reml-maxit 1000\\\n",
    " --out reml_no_constrain/test_alg{opts[0]}'\n",
    "        reml_gridsearch_cmds.append(gctacmd)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reml_gridsearch.swarm', 'w') as f:\n",
    "    for cmd in reml_gridsearch_cmds:\n",
    "        f.write(f'{cmd}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62446524\n"
     ]
    }
   ],
   "source": [
    "!swarm -f reml_gridsearch.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one that works from gridsearch\n",
    "# run for each number of pcs\n",
    "\n",
    "with open('multi_pcs_reml.swarm', 'w') as f:\n",
    "    for i in [20,40,80]:\n",
    "        \n",
    "        remlcmd = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.merged_chrs.txt\\\n",
    " --pheno _keep.id\\\n",
    " --qcovar chr1.pca.{i}.eigenvec\\\n",
    " --reml-alg 0\\\n",
    " --reml-no-constrain\\\n",
    " --thread-num 64\\\n",
    " --reml-maxit 1000\\\n",
    " --out reml/reml_2maf_alg0_{i}pcs'\n",
    "        \n",
    "        f.write(f'{remlcmd}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f multi_pcs_reml.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting H^2\n",
    "dfs = []\n",
    "for i in [20,40,80]:\n",
    "    hsq = pd.read_csv(f\"reml/reml_2maf_alg0_{i}pcs.hsq\", sep=\"\\t\")\n",
    "    hsq.columns = [\"Source\", f\"Variance{i}\", f\"SE{i}\"]\n",
    "    dfs.append(hsq)\n",
    "# hsq20 = pd.read_csv(\"reml/reml_2maf_alg0_20pcs.hsq\", sep=\"\\t\")\n",
    "# hsq40 = pd.read_csv(\"reml/reml_2maf_alg0_40pcs.hsq\", sep=\"\\t\")\n",
    "# hsq80 = pd.read_csv(\"reml/reml_2maf_alg0_80pcs.hsq\", sep=\"\\t\")\n",
    "\n",
    "# dfs = [hsq20, hsq40, hsq80]\n",
    "hsq = reduce(lambda left,right: pd.merge(left,right,on='Source'), dfs)\n",
    "hsq2 = hsq.iloc[6:11,:].reset_index().drop('index',axis=1)\n",
    "hsq2['maf_ld_group'] = ['mafbin1_ldbin1','mafbin1_ldbin2','mafbin2_ldbin1','mafbin2_ldbin2','total']\n",
    "hsq2['maf'] = ['low','low','high','high','total']\n",
    "# ['0.0001-0.01', '0.0001-0.01', '0.01-0.5', '0.01-0.5','total']\n",
    "hsq2['ld'] = ['low','high','low','high','total']\n",
    "hsq2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsq_var = hsq2[[\"Variance20\",\"Variance40\",\"Variance80\",\"maf\",\"ld\"]]\n",
    "hsq_melt = pd.melt(hsq2, id_vars=['maf','ld','SE20','SE40','SE80'],value_vars=['Variance20','Variance40','Variance80'])\n",
    "hsq_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = hsq_var_melt[hsq_var_melt.ld=='low']\n",
    "high = hsq_var_melt[hsq_var_melt.ld=='high']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "sns.barplot(low.maf, low.value, hue=low.variable, ax=ax1)\n",
    "ax1.title.set_text(\"Low LD\")\n",
    "\n",
    "sns.barplot(high.maf, high.value, hue=high.variable, ax=ax2)\n",
    "ax2.title.set_text(\"High LD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
