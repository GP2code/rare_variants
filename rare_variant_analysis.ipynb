{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import chdir\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# local import (Hirotaka's myfunctions.py script)\n",
    "import myfunctions as myfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'temp': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir temp\n",
    "chdir('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the id file, covariate file (all European)\n",
    "wgsfolder = '/data/CARD/PD/GENOMES/august19/genotypes'\n",
    "idfile = '_keep.id'\n",
    "demog = pd.read_csv('/data/LNG/iwakih2/ampPD/data1_out/PP_PD_BF_HB_LC_demog.csv')\n",
    "euro = pd.read_csv(f'{wgsfolder}/PCA_filtered_europeans.txt', sep=' ',\n",
    "                  header=None, names=['FID', 'IID'])\n",
    "df = pd.merge(demog, euro, left_on='WGSID', right_on='IID')\n",
    "df['FID'] = df.WGSID\n",
    "df['IID'] = df.WGSID\n",
    "df.RECRUIT=['CTR' if i=='HC' else i for i in df.RECRUIT]\n",
    "df = df[df.RECRUIT.isin(['CTR', 'PD'])]\n",
    "df = df[df.RECRUIT==df.LASTDIAG]\n",
    "df['pheno'] = [1 if i=='PD' else 0 for i in df.RECRUIT]\n",
    "df['AAD'] = df.AADi.where(df.pheno==0, other=df.AAOi)\n",
    "df['AGE'] = df.AGEatBL.where(df.pheno==0, other=df.AAD)\n",
    "\n",
    "df[['FID', 'IID', 'pheno']].to_csv(idfile, index=False, sep='\\t', header=None)\n",
    "df[['FID', 'IID', 'AGE', 'FEMALE']].to_csv('_qcovar.txt', index=False, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chrnum in range(1,23):\n",
    "#     pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "#     out = f'{wgsfolder}/merge/pd.june2019.chr{chrnum}.sqc'\n",
    "#     plinkcmd = f'\\\n",
    "#  plink2 --pfile {pfile}\\\n",
    "#  --make-bed\\\n",
    "#  --out {out}'\n",
    "#    myfunc.shell_do(plinkcmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_mergelist.txt', 'w') as f:\n",
    "#     for chrnum in range(1,23):\n",
    "#         bfile = f'{wgsfolder}/merge/pd.june2019.chr{chrnum}.sqc'\n",
    "#         f.write(f'{bfile}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergecmd = f'\\\n",
    "# plink --merge-list _mergelist.txt\\\n",
    "#  --make-bed\\\n",
    "#  --out {wgsfolder}/merge/pd.june2019.sqc'\n",
    "# with open('_merge_batch_script.sh', 'w') as f:\n",
    "#     f.write('#!/bin/bash\\n')\n",
    "#     f.write('module load plink\\n')\n",
    "#     f.write(f'{mergecmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sbatch _merge_batch_script.sh --cpus-per-task=128 --mem=100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used this to generate pca for chr1 just for testing purposes-- prune and merge all chrs first then run PCA\n",
    "with open('_pca.swarm', 'w') as f:\n",
    "    for chrnum in range(1,2):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        out_pcs = f'chr{chrnum}.pca'\n",
    "        plink_pca_cmd = f'\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --pca 50\\\n",
    " --out {out_pcs}\\n'\n",
    "        \n",
    "        f.write(plink_pca_cmd)\n",
    "        print(plink_pca_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _pca.swarm -g 64 --time=10:00:00 -t 20 --logdir swarm --module plink/2.0_alpha_1_final --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script1.sh', 'w') as f:\n",
    "    for chrnum in range(1,):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --keep {idfile} \\\n",
    " --freq \\\n",
    " --out {freqfile}\\n\"\n",
    "        f.write(plinkcmd)\n",
    "#         myfunc.shell_do(plinkcmd)\n",
    "print(f'{plinkcmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "# client should match the qued number of threads\n",
    "# client = Client(processes=False, threads_per_worker=2,\n",
    "#                 n_workers=2, memory_limit='30GB')\n",
    "# import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "#try testing fewer maf bins\n",
    "def MAFbin(x):\n",
    "    if x>0:\n",
    "        if x<0.001:\n",
    "            return(1)\n",
    "        elif x<0.01:\n",
    "            return(2)\n",
    "        elif x<0.1:\n",
    "            return(3)\n",
    "        elif x<0.25:\n",
    "            return(4)\n",
    "        elif x<0.5:\n",
    "            return(5)\n",
    "        else:\n",
    "            return(6)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "\n",
    "\n",
    "# def MAFbin(x):\n",
    "#     if x>0:\n",
    "#         if x<0.001:\n",
    "#             return(1)\n",
    "#         elif x<0.01:\n",
    "#             return(2)\n",
    "#         elif x<0.1:\n",
    "#             return(3)\n",
    "#         elif x<0.2:\n",
    "#             return(4)\n",
    "#         elif x<0.3:\n",
    "#             return(5)\n",
    "#         elif x<0.4:\n",
    "#             return(6)\n",
    "#         else:\n",
    "#             return(7)\n",
    "#     else:\n",
    "#         return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts_df = pd.DataFrame(index=[0,1,2,3,4,5,6])\n",
    "\n",
    "for chrnum in range(1,23):\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "\n",
    "    df = dd.read_csv(f'{freqfile}.afreq', sep='\\t')\n",
    "    df['MAF'] = df.ALT_FREQS.where(cond=df.ALT_FREQS<=0.5, other=1-df.ALT_FREQS)\n",
    "    df['Group'] = df.MAF.apply(MAFbin, meta=('MAF', 'float64'))\n",
    "    for i in range(1,7):\n",
    "        df.loc[df.Group==i, ['ID']].to_csv(\n",
    "            f'{freqfile}.mafbin{i}', index=False, single_file=True)\n",
    "    print(f'chr{chrnum} finished')\n",
    "    total_counts_df[chrnum] = pd.DataFrame(df.groupby('Group').ID.count().compute())\n",
    "#     total_counts_df.merge(counts_df, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add chr names\n",
    "chrs = ['chr' + str(i) for i in range(1,23)]\n",
    "total_counts_df.columns = chrs\n",
    "\n",
    "# add bins\n",
    "bins = ['0.000', '<0.001', '<0.01', '<0.1', '<0.25', '<0.5', '=0.5']\n",
    "total_counts_df['bin'] = bins\n",
    "total_counts_df.set_index('bin', inplace=True)\n",
    "total_counts_df['total'] = total_counts_df.sum(axis=1)\n",
    "total_counts_df.to_csv('_maf_bin_counts.txt', sep='\\t')\n",
    "total_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqfile = f'freq.21'\n",
    "\n",
    "df = pd.read_csv(f'{freqfile}.afreq', sep='\\t')\n",
    "df['MAF'] = df.ALT_FREQS.where(cond=df.ALT_FREQS<=0.5, other=1-df.ALT_FREQS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = df.MAF.apply(MAFbin)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Group == 6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_script2.swarm', 'w') as f:\n",
    "    for chrnum in range(1,23):\n",
    "        pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "        freqfile = f'freq.{chrnum}'\n",
    "        for Indx in range(1,7):\n",
    "            mafbinIndx = f'mafbin{Indx}'\n",
    "            mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "            plinkcmd = f\"\\\n",
    "plink2 --pfile {pfile}\\\n",
    " --extract {mafbinfile}\\\n",
    " --keep {idfile}\\\n",
    " --make-bed\\\n",
    " --out {mafbinfile}\"\n",
    "            gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin\\\n",
    " --thread-num 10'\n",
    "\n",
    "            f.write(f'{plinkcmd} && {gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f _script2.swarm --time=40:00:00 -g 64 -t 10 --logdir swarm --module GCTA,plink/2.0_alpha_1_final --partition=norm --devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrnum in range(1,23):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rerun for jobs that were killed\n",
    "outputs = glob.glob('freq.*.mafbin*.ldbin.score.ld')\n",
    "# len(glob.glob('*.ldbin.log'))\n",
    "expected_out = ['freq.' + str(i) + '.mafbin' + str(j) + '.ldbin.score.ld' for i in range(1,23) for j in range(1,7)]\n",
    "missing = [bed.replace('.ldbin.score.ld', '') for bed in list(set(expected_out) - set(outputs))]\n",
    "\n",
    "with open('_rerunscript.swarm', 'w') as f:\n",
    "    for mafbinfile in missing:\n",
    "        gctacmd1 = f'\\\n",
    "gcta64 --bfile {mafbinfile}\\\n",
    " --ld-score-region 10000\\\n",
    " --out {mafbinfile}.ldbin\\\n",
    " --thread-num 10'\n",
    "\n",
    "        f.write(f'{gctacmd1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f _rerunscript.swarm --time=40:00:00 -g 64 -t 10 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrnum in range(1,23):\n",
    "    pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(1,6): # leaving last maf bin out for testing!!!! ( will be combined with 0.25<maf<=0.5)\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # Note this is the ldscore within the maf bin\n",
    "        df = dd.read_csv(f'{mafbinfile}.ldbin.score.ld', sep=' ')\n",
    "        ldscvec = df.ldscore_SNP.compute()\n",
    "        ldscThres = ldscvec.median()\n",
    "        df['Group'] = 1\n",
    "        df['Group'] = df.Group.where(cond=df.ldscore_SNP<ldscThres, other=2)\n",
    "\n",
    "\n",
    "        # Create ldbin and GRMs within the ldbin\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "#             df.loc[df.Group==i, ['SNP']].to_csv(\n",
    "#                 f'{ldbinIndx}', index=False, single_file=True)\n",
    "#             gctacmd2 = f'\\\n",
    "#             gcta64 --bfile {mafbinfile}\\\n",
    "#  --extract {ldbinIndx}\\\n",
    "#  --make-grm\\\n",
    "#  --out {ldbinIndx}'\n",
    "#             myfunc.shell_do(gctacmd2)\n",
    "            with open('multi_GRMs.txt', 'a') as f:\n",
    "                f.write(f'{ldbinIndx}\\n')\n",
    "        # mafbin information save to mafbinInfo.csv\n",
    "        with open('mafbinInfo.txt', 'a') as f:\n",
    "            s = f'{chrnum}\\t{mafbinIndx}\\t{len(ldscvec)}\\t{ldscvec.mean()}\\t{ldscvec.median()}\\t{ldscvec.std()}'\n",
    "            f.write(f'{s}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create covar file per chrom and impute missing age (may want to consider dropping age column in this case (missing for more than half))\n",
    "# impute \"FEMALE\" with median\n",
    "for chrnum in range(1,2):\n",
    "    pcs_df = pd.read_csv(f'chr{chrnum}.pca.eigenvec', sep='\\t')\n",
    "    pcs_df.rename(columns={'#FID':'FID'}, inplace=True)\n",
    "    covar_df = df[['FID', 'IID', 'AGE', 'FEMALE']].merge(pcs_df, on=['FID','IID'])\n",
    "    covar_df.drop(['AGE','FEMALE'], axis=1, inplace=True)\n",
    "#     covar_df.AGE.fillna(covar_df.AGE.mean(), inplace=True)\n",
    "#     covar_df.FEMALE.fillna(covar_df.FEMALE.median(),inplace=True)\n",
    "#     print(f'dropping {covar_df[covar_df.AGE.isnull()].shape[0]} rows for missing age')\n",
    "#     covar_df.dropna(how='any', inplace=True)\n",
    "    covar_df.to_csv(f'chr{chrnum}.covar', index=False, sep=' ', header=None)\n",
    "    print(f'wrote: chr{chrnum}.covar with {covar_df.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ld_counts_dict = {i:0 for i in range(1,7)}\n",
    "low_ld_counts_dict = {i:0 for i in range(1,7)}\n",
    "\n",
    "for chrnum in range(1,23):\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(1,7):\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "            ldbin_df = pd.read_csv(ldbinIndx,sep='\\t')\n",
    "            if (i == 1):\n",
    "                high_ld_counts_dict[Indx] += ldbin_df.shape[0]\n",
    "            else:\n",
    "                low_ld_counts_dict[Indx] += ldbin_df.shape[0]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'high ld counts per maf group: {high_ld_counts_dict}')\n",
    "print(f'low ld counts per maf group: {low_ld_counts_dict}')\n",
    "high_df = pd.Series(high_ld_counts_dict).to_frame()\n",
    "low_df = pd.Series(low_ld_counts_dict).to_frame()\n",
    "high_df.columns = ['high_ld']\n",
    "low_df.columns = ['low_ld']\n",
    "ld_counts_df = high_df.merge(low_df, left_index=True, right_index=True)\n",
    "bins = ['<0.001', '<0.01', '<0.1', '<0.25', '<0.5', '=0.5']\n",
    "ld_counts_df['maf_bin'] = bins\n",
    "ld_counts_df.set_index('maf_bin', inplace=True)\n",
    "ld_counts_df.to_csv('_ld_bin_counts.txt', sep='\\t')\n",
    "ld_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--reml-no-lrt\\\n",
    "# --reml-inv-mtd 3\\\n",
    "# run with all maf bins\n",
    "gctacmd3 = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.txt\\\n",
    " --pheno {idfile}\\\n",
    " --qcovar chr1.pca.eigenvec\\\n",
    " --reml-alg 1\\\n",
    " --reml-no-constrain\\\n",
    " --thread-num 60\\\n",
    " --reml-maxit 1000\\\n",
    " --out test'\n",
    "# myfunc.shell_do(gctacmd3)\n",
    "\n",
    "with open('_reml_script.swarm', 'w') as f:\n",
    "#     f.write('#!/bin/bash\\n')\n",
    "    f.write(f'{gctacmd3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f _reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up to run with just maf bins 2-6 as we might not have resolution for maf<0.001\n",
    "for chrnum in range(1,23):\n",
    "    pfile = f'{wgsfolder}/pd.june2019.chr{chrnum}.sqc'\n",
    "    freqfile = f'freq.{chrnum}'\n",
    "    for Indx in range(2,6): # leaving last maf bin out for testing!!!! ( will be combined with 0.25<maf<=0.5)\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        mafbinfile =  f'{freqfile}.{mafbinIndx}'\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # Note this is the ldscore within the maf bin\n",
    "        df = dd.read_csv(f'{mafbinfile}.ldbin.score.ld', sep=' ')\n",
    "        ldscvec = df.ldscore_SNP.compute()\n",
    "        ldscThres = ldscvec.median()\n",
    "        df['Group'] = 1\n",
    "        df['Group'] = df.Group.where(cond=df.ldscore_SNP<ldscThres, other=2)\n",
    "\n",
    "\n",
    "        # Create ldbin and GRMs within the ldbin\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinfile}.ldbin{i}'\n",
    "\n",
    "            with open('2_5_maf_bins_multi_GRMs.txt', 'a') as f:\n",
    "                f.write(f'{ldbinIndx}\\n')\n",
    "        # mafbin information save to mafbinInfo.csv\n",
    "        with open('2_5_mafbinInfo.txt', 'a') as f:\n",
    "            s = f'{chrnum}\\t{mafbinIndx}\\t{len(ldscvec)}\\t{ldscvec.mean()}\\t{ldscvec.median()}\\t{ldscvec.std()}'\n",
    "            f.write(f'{s}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gctacmd_2_5_maf = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm 2_5_maf_bins_multi_GRMs.txt\\\n",
    " --pheno {idfile}\\\n",
    " --qcovar chr1.pca.eigenvec\\\n",
    " --reml-alg 2\\\n",
    " --reml-no-constrain\\\n",
    " --thread-num 64\\\n",
    " --reml-maxit 1000\\\n",
    " --out test_2_5_maf'\n",
    "# myfunc.shell_do(gctacmd3)\n",
    "\n",
    "with open('2_5_maf_bins_reml_script.swarm', 'w') as f:\n",
    "#     f.write('#!/bin/bash\\n')\n",
    "    f.write(f'{gctacmd_2_5_maf}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f 2_5_maf_bins_reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get estimates for cpu-hrs for analysis\n",
    "jobs_df = pd.read_csv('../biowulf_user_dashboard.csv')\n",
    "jobs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df2 = jobs_df[jobs_df.state == 'COMPLETED'][['jobid','cpu', 'cpu_min',\n",
    "       'cpu_max', 'cpu_avg', 'cpu_util', 'mem', 'mem_min', 'mem_max','elapsed_time']]\n",
    "\n",
    "jobs_df2['hrs'] = jobs_df2.elapsed_time/3600\n",
    "jobs_df2['cpu_hrs'] = jobs_df2.cpu * jobs_df2.hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(jobs_df2.cpu_hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try merging grms\n",
    "\n",
    "# !gcta --mgrm multi_GRMs.txt --make-grm --out test_merged_grm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gctacmd_merged = f'\\\n",
    "# gcta --reml\\\n",
    "#  --grm test_merged_grm\\\n",
    "#  --pheno {idfile}\\\n",
    "#  --qcovar chr1.pca.eigenvec\\\n",
    "#  --reml-alg 2\\\n",
    "#  --reml-no-constrain\\\n",
    "#  --thread-num 64\\\n",
    "#  --reml-maxit 1000\\\n",
    "#  --out test_merged'\n",
    "\n",
    "# with open('merged_reml_script.swarm', 'w') as f:\n",
    "# #     f.write('#!/bin/bash\\n')\n",
    "#     f.write(f'{gctacmd_merged}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !swarm -f merged_reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ids = pd.read_csv('_keep.id',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ids[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: gcta --mgrm multi_GRMs.mafbin1.ldbin1.txt --make-grm --out freq.mafbin1.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin1.ldbin2.txt --make-grm --out freq.mafbin1.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin2.ldbin1.txt --make-grm --out freq.mafbin2.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin2.ldbin2.txt --make-grm --out freq.mafbin2.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin3.ldbin1.txt --make-grm --out freq.mafbin3.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin3.ldbin2.txt --make-grm --out freq.mafbin3.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin4.ldbin1.txt --make-grm --out freq.mafbin4.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin4.ldbin2.txt --make-grm --out freq.mafbin4.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin5.ldbin1.txt --make-grm --out freq.mafbin5.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin5.ldbin2.txt --make-grm --out freq.mafbin5.ldbin2\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin6.ldbin1.txt --make-grm --out freq.mafbin6.ldbin1\n",
      "Executing: gcta --mgrm multi_GRMs.mafbin6.ldbin2.txt --make-grm --out freq.mafbin6.ldbin2\n"
     ]
    }
   ],
   "source": [
    "# now merge chr grms (1 grm per mafbin/ldbin combo: 6 maf bins, 2 ldbins = 12 total grms)\n",
    "\n",
    "with open('multi_GRMs.merged_chrs.txt', 'w') as mergedGRMlist:\n",
    "    for Indx in range(1,7):\n",
    "        mafbinIndx = f'mafbin{Indx}'\n",
    "        for i in range(1, 3):\n",
    "            ldbinIndx = f'{mafbinIndx}.ldbin{i}'\n",
    "            for chrnum in range(1,23):\n",
    "                freqfile = f'freq.{chrnum}.{ldbinIndx}'\n",
    "                multiGRMfile = f'multi_GRMs.{ldbinIndx}.txt'\n",
    "                mergedGRMfile = f'freq.{ldbinIndx}'\n",
    "                with open(f'{multiGRMfile}', 'a') as f:\n",
    "                    f.write(f'{freqfile}\\n')\n",
    "            \n",
    "            gcta_merge_cmd = f'\\\n",
    "gcta --mgrm {multiGRMfile}\\\n",
    " --make-grm --out {mergedGRMfile}'\n",
    "            myfunc.shell_do(gcta_merge_cmd)\n",
    "            mergedGRMlist.write(f'{mergedGRMfile}\\n')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gctacmd_merged_chrs_reml = f'\\\n",
    "gcta --reml\\\n",
    " --mgrm multi_GRMs.merged_chrs.txt\\\n",
    " --pheno {idfile}\\\n",
    " --qcovar chr1.pca.eigenvec\\\n",
    " --reml-no-constrain\\\n",
    " --thread-num 64\\\n",
    " --reml-maxit 1000\\\n",
    " --out test'\n",
    "\n",
    "with open('_reml_script.swarm', 'w') as f:\n",
    "    f.write(f'{gctacmd_merged_chrs_reml}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61592990\n"
     ]
    }
   ],
   "source": [
    "!swarm -f _reml_script.swarm --time=80:00:00 -g 64 -t 64 --logdir swarm --module GCTA --partition=norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
